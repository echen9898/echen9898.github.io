---
layout: post
title: "Autonomous RC Car"
image: "/assets/profiles/car.jpg"
date: 2019-05-15
skills: "ROS, Tensorflow, Python, OpenCV, Linux"
---

___

<p>&nbsp;</p>
**Resources: [code](https://github.mit.edu/rss2019-11){:target="_blank"}, [final Video](https://www.youtube.com/watch?v=xLZU6TcSmRo&feature=youtu.be){:target="_blank"}**
<p>&nbsp;</p>

6.141 (Robotics, Science and Systems) is a robotics lab at MIT that covers perception, control, planning, and embedded system development for autonomous systems. Our team of 4 used ROS to implement a variety of algorithms on a robot car equipped with lidar and camera sensors. The class culminated in an autonomous race around a non-oval track, and autonomous navigation on an urban course with street signs and pedestrians. 

For the race, we implemented a safety controller and trajectory tracking capable of operating reliably at high speeds. For the autonomous navigation challenge, we designed a complete system capable of lane following, object recognition, and multilevel control. The car was able to autonomously obey a variety of traffic signs, switch lanes to avoid obstacles and pedestrians, and park in a designated spot at the end of the course. Reports and presentations below.

#### Localization:
* [Report]({% link /assets/2019-05-15/localization_report.pdf %}){:target="_blank"}
* [Presentation]({% link /assets/2019-05-15/localization_presentation.pdf %}){:target="_blank"}

#### Planning/Trajectory Tracking:
* [Report]({% link /assets/2019-05-15/planning_report.pdf %}){:target="_blank"}
* [Presentation]({% link /assets/2019-05-15/planning_presentation.pdf %}){:target="_blank"}

#### Autonomous Navigation:
* [Report]({% link /assets/2019-05-15/final_report.pdf %}){:target="_blank"}
* [Presentation]({% link /assets/2019-05-15/final_presentation.pdf %}){:target="_blank"}

<img src="/assets/2019-05-15/demo.gif" alt="Lane following demo" class="center blog_post_body">
